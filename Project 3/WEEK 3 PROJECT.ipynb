{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC END TO END EXTRACT TRANSFORM LOAD(ETL) PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "                .appName(\"Stack Overflow Data Wrangling\")\n",
    "                .config(\"spark.jars\",\"C:\\\\Users\\\\Z\\\\Documents\\\\blossom\\\\postgresql-42.2.8.jar\") \n",
    "                .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                      Load data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.getOrCreate()\n",
    "questions = spark.read.csv(\"questions.csv\", header=True, inferSchema=True, escape='\"', multiLine=True)\n",
    "answers = spark.read.csv(\"answers.csv\" , header=True, inferSchema=True, escape='\"', multiLine=True)\n",
    "users = spark.read.csv(\"users.csv\", header=True, inferSchema=True, escape='\"', multiLine=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Rename Columns of dataframe to   prevent Ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions.withColumnRenamed('id', 'questions_id')\n",
    "answers = answers.withColumnRenamed('id', 'answers_id')\n",
    "users = users.withColumnRenamed('id', 'users_id')\n",
    "questions = questions.withColumnRenamed('created_at', 'questions_created_at')\n",
    "answers = answers.withColumnRenamed('created_at', 'answers_created_at')\n",
    "users = users.withColumnRenamed('created_at', 'users_created_at')\n",
    "questions = questions.withColumnRenamed( 'body','questions_body')\n",
    "answers = answers.withColumnRenamed( 'body','answers_body')\n",
    "questions = questions.withColumnRenamed('user_id', 'questions_user_id')\n",
    "answers = answers.withColumnRenamed('user_id', 'answers_user_id')\n",
    "answers = answers.withColumnRenamed('question_id', 'answers_question_id')\n",
    "questions = questions.withColumnRenamed( 'score','questions_score')\n",
    "answers = answers.withColumnRenamed( 'score','answers_score')\n",
    "questions = questions.withColumnRenamed( 'comment_count','questions_comment_count')\n",
    "answers = answers.withColumnRenamed( 'comment_count','answers_comment_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select from User table where location is \"India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.registerTempTable('new_users')\n",
    "new_users = spark.sql(\"select * from new_users where location like '%India%' \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove middle towns from location columns with regular expression and split city from country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users = new_users.withColumn(\"location\", F.regexp_replace('location', r\"[,]\\s*\\w*\\s*[,]\", ','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users_updated = new_users.withColumn('location', F.split(new_users.location, ',')).select('users_id', 'display_name', 'reputation', 'website_url', \n",
    "                                    'location', 'about_me', 'views', 'up_votes', \n",
    "                                    'down_votes', 'image_url', 'users_created_at', \n",
    "                                    'updated_at', F.element_at(F.col('location'),-2).alias('city')\n",
    "        , F.element_at(F.col('location'), -1).alias('country'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|              city|country|\n",
      "+------------------+-------+\n",
      "|         Bangalore|  India|\n",
      "|         Jalandhar|  India|\n",
      "|    Madhya Pradesh|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|       West Bengal|  India|\n",
      "|         Bangalore|  India|\n",
      "|              Pune|  India|\n",
      "|       Maharashtra|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|         Bengaluru|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|             Delhi|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|              Pune|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|            Mumbai|  India|\n",
      "|              Pune|  India|\n",
      "|    Madhya Pradesh|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|         Bangalore|  India|\n",
      "|         Ahmedabad|  India|\n",
      "|         Hyderabad|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|            Mumbai|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|         Bangalore|  India|\n",
      "|         Ahmedabad|  India|\n",
      "|     Uttar Pradesh|  India|\n",
      "|       Gandhinagar|  India|\n",
      "|         New Delhi|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|              Pune|  India|\n",
      "|            Kohima|  India|\n",
      "|            Nashik|  India|\n",
      "|    Madhya Pradesh|  India|\n",
      "|     Uttar Pradesh|  India|\n",
      "|              null|  India|\n",
      "|              null|  India|\n",
      "|         Bangalore|  India|\n",
      "|         Hyderabad|  India|\n",
      "|              Pune|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|         Faridabad|  India|\n",
      "|            Mumbai|  India|\n",
      "|              Pune|  India|\n",
      "|              Pune|  India|\n",
      "|             Udupi|  India|\n",
      "|         Bangalore|  India|\n",
      "|          Pasodara|  India|\n",
      "|       West Bengal|  India|\n",
      "|         New Delhi|  India|\n",
      "|         Hyderabad|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|            Mumbai|  India|\n",
      "|         Hyderabad|  India|\n",
      "|       Bhubaneswar|  India|\n",
      "|              Pune|  India|\n",
      "|            Mumbai|  India|\n",
      "|              null|  India|\n",
      "|       West Bengal|  India|\n",
      "|         Bangalore|  India|\n",
      "|        Trivandrum|  India|\n",
      "|         Bengaluru|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|         New Delhi|  India|\n",
      "|            Nashik|  India|\n",
      "|              null|  India|\n",
      "|         Bangalore|  India|\n",
      "|           Indiana|    USA|\n",
      "|            Mumbai|  India|\n",
      "|        Hazaribagh|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|              null|  India|\n",
      "|              Pune|  India|\n",
      "|       West Bengal|  India|\n",
      "|              null|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|        Chandigarh|  India|\n",
      "|          Gurugram|  India|\n",
      "|       Bhubaneswar|  India|\n",
      "|              Pune|  India|\n",
      "|            Jaipur|  India|\n",
      "|          Vadodara|  India|\n",
      "|         Bangalore|  India|\n",
      "|            Nagpur|  India|\n",
      "|       West Bengal|  India|\n",
      "|        Tamil Nadu|  India|\n",
      "|       Bhubaneswar|  India|\n",
      "|     Uttar Pradesh|  India|\n",
      "|              null|  India|\n",
      "|Switzerland County|    USA|\n",
      "|         Bangalore|  India|\n",
      "|              null|  India|\n",
      "|         Jalandhar|  India|\n",
      "|         Bengaluru|  India|\n",
      "+------------------+-------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_users_updated.select('city','country').show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join  users table appended with city and country to questions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users_questions = new_users_updated.join(questions, new_users_updated.users_id == questions.questions_user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter new joint table where view_count column is 20 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users_questions.registerTempTable('new_users_questions_temp')\n",
    "new_users_questions_temp = spark.sql(\"select * from new_users_questions_temp where view_count > 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = new_users_questions_temp.join(answers, new_users_questions_temp.users_id == answers.answers_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('users_id', 'int'),\n",
       " ('display_name', 'string'),\n",
       " ('reputation', 'int'),\n",
       " ('website_url', 'string'),\n",
       " ('location', 'array<string>'),\n",
       " ('about_me', 'string'),\n",
       " ('views', 'int'),\n",
       " ('up_votes', 'int'),\n",
       " ('down_votes', 'int'),\n",
       " ('image_url', 'string'),\n",
       " ('users_created_at', 'timestamp'),\n",
       " ('updated_at', 'timestamp'),\n",
       " ('city', 'string'),\n",
       " ('country', 'string'),\n",
       " ('questions_id', 'int'),\n",
       " ('questions_user_id', 'int'),\n",
       " ('title', 'string'),\n",
       " ('questions_body', 'string'),\n",
       " ('accepted_answer_id', 'int'),\n",
       " ('questions_score', 'int'),\n",
       " ('view_count', 'int'),\n",
       " ('questions_comment_count', 'int'),\n",
       " ('questions_created_at', 'timestamp'),\n",
       " ('answers_id', 'int'),\n",
       " ('answers_user_id', 'int'),\n",
       " ('answers_question_id', 'int'),\n",
       " ('answers_body', 'string'),\n",
       " ('answers_score', 'int'),\n",
       " ('answers_comment_count', 'int'),\n",
       " ('answers_created_at', 'timestamp')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select minimum time from updated_at column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.registerTempTable('temp_results')\n",
    "temp_results = spark.sql(\"select min(updated_at) from temp_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|    min(updated_at)|\n",
      "+-------------------+\n",
      "|2019-02-02 02:07:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write dataframe to results table in  Schema stackoverflow_filtered  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.write.format(\"jdbc\").options(\n",
    "   url='jdbc:postgresql://localhost:5432/postgres',\n",
    "   driver='org.postgresql.Driver',\n",
    "   user='postgres',\n",
    "   password='postgres',\n",
    "   dbtable='stackoverflow_filtered.results'\n",
    ").save(mode='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIFFERENCES BETWEEN VIEWS AND MATERIALIZED VIEWS:\n",
    "\n",
    "#### -  The basic difference between View and Materialized View is that Views are not stored physically on the disk.  On the other hands, Materialized Views are stored on the disc.\n",
    "\n",
    "#### -  View can be defined as a virtual table created as a result of the query expression. However, Materialized View is a physical copy, picture or snapshot of the base table.\n",
    "\n",
    "#### -  A view is always updated as the query creating View executes each time the View is used. On the other hands, Materialized View is updated manually or by applying triggers to it.\n",
    "\n",
    "#### -  Materialized View responds faster than View as the Materialized View is precomputed.\n",
    "\n",
    "#### -  Materialized View utilizes the memory space as it stored on the disk whereas, the View is just a display hence it do not require memory space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SQL DATA MANIPULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  142 cities appeared more than twice in my results table\n",
    "### 2.  There are 1,957 unique created_at dates in my results table\n",
    "### 3. I will give an award to user name 'Bhuvanesh BS' because he has the highest answer_score of 85 from the results table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
